2022-10-15T17:16:55 (svs.sh:205:main) ./svs.sh --lang jp --stage 6 --stop_stage 6 --local_data_opts --stage 0 --feats_type raw --pitch_extract None --fs 24000 --fmax 7600 --fmin 80 --n_fft 2048 --n_shift 300 --win_length 1200 --token_type phn --g2p pyopenjtalk --cleaner none --train_config conf/tuning/train_naive_rnn_dp_alf.yaml --inference_config conf/decode.yaml --train_set tr_no_dev --valid_set dev --test_sets dev eval --score_feats_extract syllable_score_feats --srctexts data/tr_no_dev/text --svs_exp exp/rnn-dp-alf-beat_predict_3 --audio_format wav
2022-10-15T17:16:56 (svs.sh:647:main) Stage 6: SVS Training: train_set=dump/raw/tr_no_dev, valid_set=dump/raw/dev
2022-10-15T17:16:56 (svs.sh:843:main) Generate 'exp/rnn-dp-alf-beat_predict_3/run.sh'. You can resume the process from stage 6 using this script
2022-10-15T17:16:56 (svs.sh:848:main) SVS training started... log: 'exp/rnn-dp-alf-beat_predict_3/train.log'
2022-10-15 17:16:56,832 (launch:94) INFO: /root/anaconda3/envs/espnet/bin/python3 /data1/wyn/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/rnn-dp-alf-beat_predict_3/train.log' --log exp/rnn-dp-alf-beat_predict_3/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/rnn-dp-alf-beat_predict_3/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.svs_train --use_preprocessor true --token_type phn --token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt --syb_token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt_syb --non_linguistic_symbols none --cleaner none --g2p pyopenjtalk --normalize global_mvn --resume true --init_param --ignore_init_mismatch false --fold_length 150 --fold_length 240000 --output_dir exp/rnn-dp-alf-beat_predict_3 --config conf/tuning/train_naive_rnn_dp_alf.yaml --score_feats_extract syllable_score_feats --score_feats_extract_conf fs=24000 --score_feats_extract_conf n_fft=2048 --score_feats_extract_conf win_length=1200 --score_feats_extract_conf hop_length=300 --feats_extract fbank --feats_extract_conf n_fft=2048 --feats_extract_conf hop_length=300 --feats_extract_conf win_length=1200 --pitch_extract None --feats_extract_conf fs=24000 --feats_extract_conf fmin=80 --feats_extract_conf fmax=7600 --feats_extract_conf n_mels=80 --train_data_path_and_name_and_type dump/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/raw/tr_no_dev/wav.scp,singing,sound --train_data_path_and_name_and_type dump/raw/tr_no_dev/label,label,duration --train_data_path_and_name_and_type dump/raw/tr_no_dev/xml.scp,midi,midi --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/singing_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/durations_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/score_shape --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,singing,sound --valid_data_path_and_name_and_type dump/raw/dev/label,label,duration --valid_data_path_and_name_and_type dump/raw/dev/xml.scp,midi,midi --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/singing_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/durations_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/score_shape --normalize_conf stats_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz
2022-10-15 17:16:56,880 (launch:348) INFO: log file: exp/rnn-dp-alf-beat_predict_3/train.log
run.pl: job failed, log is in exp/rnn-dp-alf-beat_predict_3/train.log
Command '['run.pl', '--name', 'exp/rnn-dp-alf-beat_predict_3/train.log', '--gpu', '1', 'exp/rnn-dp-alf-beat_predict_3/train.log', 'python3', '-m', 'espnet2.bin.svs_train', '--use_preprocessor', 'true', '--token_type', 'phn', '--token_list', 'data/token_list/phn_pyopenjtalk_jp/tokens.txt', '--syb_token_list', 'data/token_list/phn_pyopenjtalk_jp/tokens.txt_syb', '--non_linguistic_symbols', 'none', '--cleaner', 'none', '--g2p', 'pyopenjtalk', '--normalize', 'global_mvn', '--resume', 'true', '--init_param', '--ignore_init_mismatch', 'false', '--fold_length', '150', '--fold_length', '240000', '--output_dir', 'exp/rnn-dp-alf-beat_predict_3', '--config', 'conf/tuning/train_naive_rnn_dp_alf.yaml', '--score_feats_extract', 'syllable_score_feats', '--score_feats_extract_conf', 'fs=24000', '--score_feats_extract_conf', 'n_fft=2048', '--score_feats_extract_conf', 'win_length=1200', '--score_feats_extract_conf', 'hop_length=300', '--feats_extract', 'fbank', '--feats_extract_conf', 'n_fft=2048', '--feats_extract_conf', 'hop_length=300', '--feats_extract_conf', 'win_length=1200', '--pitch_extract', 'None', '--feats_extract_conf', 'fs=24000', '--feats_extract_conf', 'fmin=80', '--feats_extract_conf', 'fmax=7600', '--feats_extract_conf', 'n_mels=80', '--train_data_path_and_name_and_type', 'dump/raw/tr_no_dev/text,text,text', '--train_data_path_and_name_and_type', 'dump/raw/tr_no_dev/wav.scp,singing,sound', '--train_data_path_and_name_and_type', 'dump/raw/tr_no_dev/label,label,duration', '--train_data_path_and_name_and_type', 'dump/raw/tr_no_dev/xml.scp,midi,midi', '--train_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn', '--train_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/singing_shape', '--train_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/durations_shape', '--train_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/score_shape', '--valid_data_path_and_name_and_type', 'dump/raw/dev/text,text,text', '--valid_data_path_and_name_and_type', 'dump/raw/dev/wav.scp,singing,sound', '--valid_data_path_and_name_and_type', 'dump/raw/dev/label,label,duration', '--valid_data_path_and_name_and_type', 'dump/raw/dev/xml.scp,midi,midi', '--valid_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn', '--valid_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/singing_shape', '--valid_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/durations_shape', '--valid_shape_file', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/score_shape', '--normalize_conf', 'stats_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/root/anaconda3/envs/espnet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/root/anaconda3/envs/espnet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data1/wyn/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/data1/wyn/espnet/espnet2/bin/launch.py", line 377, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/rnn-dp-alf-beat_predict_3/train.log ###################
# python3 -m espnet2.bin.svs_train --use_preprocessor true --token_type phn --token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt --syb_token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt_syb --non_linguistic_symbols none --cleaner none --g2p pyopenjtalk --normalize global_mvn --resume true --init_param --ignore_init_mismatch false --fold_length 150 --fold_length 240000 --output_dir exp/rnn-dp-alf-beat_predict_3 --config conf/tuning/train_naive_rnn_dp_alf.yaml --score_feats_extract syllable_score_feats --score_feats_extract_conf fs=24000 --score_feats_extract_conf n_fft=2048 --score_feats_extract_conf win_length=1200 --score_feats_extract_conf hop_length=300 --feats_extract fbank --feats_extract_conf n_fft=2048 --feats_extract_conf hop_length=300 --feats_extract_conf win_length=1200 --pitch_extract None --feats_extract_conf fs=24000 --feats_extract_conf fmin=80 --feats_extract_conf fmax=7600 --feats_extract_conf n_mels=80 --train_data_path_and_name_and_type dump/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/raw/tr_no_dev/wav.scp,singing,sound --train_data_path_and_name_and_type dump/raw/tr_no_dev/label,label,duration --train_data_path_and_name_and_type dump/raw/tr_no_dev/xml.scp,midi,midi --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/singing_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/durations_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/score_shape --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,singing,sound --valid_data_path_and_name_and_type dump/raw/dev/label,label,duration --valid_data_path_and_name_and_type dump/raw/dev/xml.scp,midi,midi --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/singing_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/durations_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/score_shape --normalize_conf stats_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz --ngpu 1 --multiprocessing_distributed True 
# Started at Sat Oct 15 17:16:56 UTC 2022
#
/root/anaconda3/envs/espnet/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
/root/anaconda3/envs/espnet/bin/python3 /data1/wyn/espnet/espnet2/bin/svs_train.py --use_preprocessor true --token_type phn --token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt --syb_token_list data/token_list/phn_pyopenjtalk_jp/tokens.txt_syb --non_linguistic_symbols none --cleaner none --g2p pyopenjtalk --normalize global_mvn --resume true --init_param --ignore_init_mismatch false --fold_length 150 --fold_length 240000 --output_dir exp/rnn-dp-alf-beat_predict_3 --config conf/tuning/train_naive_rnn_dp_alf.yaml --score_feats_extract syllable_score_feats --score_feats_extract_conf fs=24000 --score_feats_extract_conf n_fft=2048 --score_feats_extract_conf win_length=1200 --score_feats_extract_conf hop_length=300 --feats_extract fbank --feats_extract_conf n_fft=2048 --feats_extract_conf hop_length=300 --feats_extract_conf win_length=1200 --pitch_extract None --feats_extract_conf fs=24000 --feats_extract_conf fmin=80 --feats_extract_conf fmax=7600 --feats_extract_conf n_mels=80 --train_data_path_and_name_and_type dump/raw/tr_no_dev/text,text,text --train_data_path_and_name_and_type dump/raw/tr_no_dev/wav.scp,singing,sound --train_data_path_and_name_and_type dump/raw/tr_no_dev/label,label,duration --train_data_path_and_name_and_type dump/raw/tr_no_dev/xml.scp,midi,midi --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/singing_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/durations_shape --train_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/train/score_shape --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,singing,sound --valid_data_path_and_name_and_type dump/raw/dev/label,label,duration --valid_data_path_and_name_and_type dump/raw/dev/xml.scp,midi,midi --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/singing_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/durations_shape --valid_shape_file exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/score_shape --normalize_conf stats_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz --ngpu 1 --multiprocessing_distributed True
[neptune_wyn_2245] 2022-10-15 17:17:00,454 (svs:335) INFO: Vocabulary size: 42
[neptune_wyn_2245] 2022-10-15 17:17:00,946 (svs:367) INFO: args:Namespace(accum_grad=1, allow_variable_data_keys=False, batch_bins=1000000, batch_size=16, batch_type='sorted', best_model_criterion=[['valid', 'loss', 'min'], ['train', 'loss', 'min']], bpemodel=None, chunk_length=500, chunk_shift_ratio=0.5, cleaner=None, collect_stats=False, config='conf/tuning/train_naive_rnn_dp_alf.yaml', create_graph_in_tensorboard=False, cudnn_benchmark=False, cudnn_deterministic=True, cudnn_enabled=True, detect_anomaly=False, dist_backend='nccl', dist_init_method='env://', dist_launcher=None, dist_master_addr=None, dist_master_port=None, dist_rank=None, dist_world_size=None, distributed=False, dry_run=False, early_stopping_criterion=('valid', 'loss', 'min'), energy_extract=None, energy_extract_conf={}, energy_normalize=None, energy_normalize_conf={}, feats_extract='fbank', feats_extract_conf={'n_fft': 2048, 'hop_length': 300, 'win_length': 1200, 'fs': 24000, 'fmin': 80, 'fmax': 7600, 'n_mels': 80}, fold_length=[150, 240000], freeze_param=[], fs=24000, g2p='pyopenjtalk', grad_clip=1.0, grad_clip_type=2.0, grad_noise=False, ignore_init_mismatch=False, init_param=[], iterator_type='sequence', keep_nbest_models=2, local_rank=0, log_interval=None, log_level='INFO', max_cache_fd=32, max_cache_size=0.0, max_epoch=500, model_conf={}, multiple_iterator=False, multiprocessing_distributed=False, nbest_averaging_interval=0, ngpu=1, no_forward_run=False, non_linguistic_symbols=None, normalize='global_mvn', normalize_conf={'stats_file': 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz'}, num_att_plot=3, num_cache_chunks=1024, num_iters_per_epoch=None, num_workers=8, odim=None, optim='adam', optim_conf={'lr': 0.001, 'eps': 1e-06, 'weight_decay': 0.0}, output_dir='exp/rnn-dp-alf-beat_predict_3', patience=None, pitch_extract=None, pitch_extract_conf={}, pitch_normalize=None, pitch_normalize_conf={}, pretrain_path=None, print_config=False, required=['output_dir', 'token_list'], resume=True, scheduler=None, scheduler_conf={}, score_feats_extract='syllable_score_feats', score_feats_extract_conf={'fs': 24000, 'n_fft': 2048, 'win_length': 1200, 'hop_length': 300}, seed=0, sharded_ddp=False, sort_batch='descending', sort_in_batch='descending', svs='naive_rnn_dp_alf', svs_conf={'midi_dim': 129, 'embed_dim': 512, 'tempo_dim': 700, 'eprenet_conv_layers': 0, 'eprenet_conv_chans': 256, 'eprenet_conv_filts': 3, 'elayers': 3, 'eunits': 256, 'ebidirectional': True, 'midi_embed_integration_type': 'add', 'dlayers': 2, 'dunits': 256, 'dbidirectional': True, 'postnet_layers': 5, 'postnet_chans': 512, 'postnet_filts': 5, 'use_batch_norm': True, 'reduction_factor': 1, 'eprenet_dropout_rate': 0.2, 'edropout_rate': 0.1, 'ddropout_rate': 0.1, 'postnet_dropout_rate': 0.5, 'init_type': 'pytorch', 'use_masking': True}, syb_token_list=['<blank>', '<unk>', 'i', 'N', 'o', 'n_o', 'w_a', 'k_a', 'a', 't_a', 'r_a', 'k_o', 'u', 'm_a', 'n_a', 'n_i', 't_o', 'sh_i', 'k_u', 's_a', 'e', 'r_i', 't_e', 'k_i', 'y_o', 'ts_u', 'm_o', 'y_a', 'g_a', 'r_u', 'm_i', 'r_e', 'd_a', 'd_e', 'm_e', 'r_o', 'n_e', 's_u', 'd_o', 'k_e', 'ch_i', 's_o', 'z_u', 'h_i', 's_e', 'y_u', 'g_o', 'b_a', 'm_u', 'b_o', 'f_u', 'b_e', 'ch_a', 'b_i', 'sh_o', 'h_o', 'g_i', 'p_o', 'w_o', 'p_i', 'ry_a', 'z_o', 'p_u', 'j_i', 'sh_a', 'g_e', 'g_u', 'ty_a', 'n_u', 'z_a', 'p_o_cl', 'ch_o', 'ch_u', 'j_o', 'sh_u', 'b_u', 'j_a', 'h_e', 'i_cl', 'py_a', 'my_a', 'ch_a_cl', 'z_e', 't_i', 'dy_a', 'd_i', 'k_u_a', 'g_u_a', 'w_i', 'p_a', 'ny_a', 'hy_a', 'by_a', 'ky_a', 'k_u_u', 'v_i', 'p_i_cl', 'o_cl', 'v_a', 'ty_o', 'by_e', 'gy_a', 'k_u_o', 'k_u_e', 'w_e', 'v_e', 'j_u', 'a_cl', 'ky_o', 'dy_o', 'dy_u', 'y_e', 'k_u_i', 'g_u_o', 'g_u_u', 't_u', 'd_u', 'v_u', 'f_u_cl', 'ry_u', 'sh_e', 'ts_a', 'ty_u', 'dy_e', 'ny_u', 'hy_o', 'by_u', 'py_u', 'ky_e', 'gy_e', 'g_u_i', 'g_u_e', 'my_o', 'my_e', 'ry_o', 'sh_o_cl', 'k_u_cl', 'm_o_cl', 'p_e', 's_i', 'z_i', 'j_e', 'ch_e', 'ny_o', 'ny_e', 'hy_u', 'hy_e', 'by_o', 'py_o', 'py_e', 'f_a', 'f_e', 'my_u', 'ry_e', 'r_o_cl', 'h_a_cl', 'k_o_cl', 'z_u_cl', 'd_o_cl', 'ts_o', 'ts_i', 'ts_e', 'ky_u', 'gy_o', 'gy_u', 'f_o', 'f_i', 'ch_i_cl', 'n_i_cl', 'g_a_cl', 'r_a_cl', 'm_a_cl', 'b_o_cl', 'N_cl', 'y_a_cl', 's_e_cl', 'd_a_cl', 'y_o_cl', 'k_u_o_cl', 't_i_cl', 'd_i_cl', 'n_a_cl', '<sos/eos>'], token_list=['<blank>', '<unk>', 'a', 'o', 'i', 'u', 'e', 'k', 'n', 'r', 't', 'm', 'N', 's', 'y', 'd', 'g', 'w', 'sh', 'b', 'h', 'ch', 'cl', 'ts', 'p', 'z', 'I', 'U', 'j', 'f', 'ry', 'v', 'ty', 'my', 'ny', 'by', 'py', 'dy', 'hy', 'ky', 'gy', '<sos/eos>'], token_type='phn', train_data_path_and_name_and_type=[('dump/raw/tr_no_dev/text', 'text', 'text'), ('dump/raw/tr_no_dev/wav.scp', 'singing', 'sound'), ('dump/raw/tr_no_dev/label', 'label', 'duration'), ('dump/raw/tr_no_dev/xml.scp', 'midi', 'midi')], train_dtype='float32', train_shape_file=['exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/singing_shape', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/durations_shape', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/train/score_shape'], unused_parameters=False, use_amp=False, use_matplotlib=True, use_preprocessor=True, use_tensorboard=True, use_wandb=False, val_scheduler_criterion=('valid', 'loss'), valid_batch_bins=None, valid_batch_size=None, valid_batch_type=None, valid_data_path_and_name_and_type=[('dump/raw/dev/text', 'text', 'text'), ('dump/raw/dev/wav.scp', 'singing', 'sound'), ('dump/raw/dev/label', 'label', 'duration'), ('dump/raw/dev/xml.scp', 'midi', 'midi')], valid_max_cache_size=None, valid_shape_file=['exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/singing_shape', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/durations_shape', 'exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/score_shape'], version='202209', wandb_entity=None, wandb_id=None, wandb_model_log_interval=-1, wandb_name=None, wandb_project=None, write_collected_feats=False)
[neptune_wyn_2245] 2022-10-15 17:17:03,966 (abs_task:1157) INFO: pytorch.version=1.9.0, cuda.available=True, cudnn.version=7605, cudnn.benchmark=False, cudnn.deterministic=True
[neptune_wyn_2245] 2022-10-15 17:17:03,971 (abs_task:1158) INFO: Model structure:
ESPnetSVSModel(
  (text_extract): SyllableScoreFeats(win_length=1200, hop_length=300, center=True, )
  (feats_extract): LogMelFbank(
    (stft): Stft(n_fft=2048, win_length=1200, hop_length=300, center=True, normalized=False, onesided=True)
    (logmel): LogMel(sr=24000, n_fft=2048, n_mels=80, fmin=80, fmax=7600, htk=False)
  )
  (score_feats_extract): SyllableScoreFeats(win_length=1200, hop_length=300, center=True, )
  (label_extract): SyllableScoreFeats(win_length=1200, hop_length=300, center=True, )
  (tempo_extract): SyllableScoreFeats(win_length=1200, hop_length=300, center=True, )
  (beat_extract): SyllableScoreFeats(win_length=1200, hop_length=300, center=True, )
  (normalize): GlobalMVN(stats_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (svs): NaiveRNNDPALF(
    (syllable_input_layer): Embedding(183, 256, padding_idx=0)
    (midi_syb_input_layer): Embedding(129, 256, padding_idx=0)
    (beat_syb_input_layer): Embedding(700, 256, padding_idx=0)
    (phoneme_segmentation_predictor): PhonemeSegmentationPredictor(
      (conv): ModuleList(
        (0): Sequential(
          (0): Conv1d(512, 384, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
          (2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
          (3): Dropout(p=0.1, inplace=False)
        )
        (1): Sequential(
          (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
          (2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
          (3): Dropout(p=0.1, inplace=False)
        )
      )
      (linear): Linear(in_features=384, out_features=4, bias=True)
    )
    (phoneme_length_regulator): PhonemeLengthRegulator()
    (encoder_input_layer): Embedding(42, 256, padding_idx=0)
    (midi_encoder_input_layer): Embedding(129, 256, padding_idx=0)
    (tempo_encoder_input_layer): Embedding(700, 256, padding_idx=0)
    (syb_encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (midi_syb_encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (tempo_syb_encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (seg_loss): MSELoss()
    (encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (midi_encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (tempo_encoder): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)
    (midi_projection): Linear(in_features=512, out_features=512, bias=True)
    (duration_predictor): DurationPredictor(
      (conv): ModuleList(
        (0): Sequential(
          (0): Conv1d(512, 384, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
          (2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
          (3): Dropout(p=0.1, inplace=False)
        )
        (1): Sequential(
          (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
          (2): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
          (3): Dropout(p=0.1, inplace=False)
        )
      )
      (linear): Linear(in_features=384, out_features=1, bias=True)
    )
    (length_regulator): LengthRegulator()
    (decoder): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)
    (feat_out): Linear(in_features=512, out_features=80, bias=True)
    (postnet): Postnet(
      (postnet): ModuleList(
        (0): Sequential(
          (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (2): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (3): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (4): Sequential(
          (0): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (criterion): FeedForwardTransformerLoss(
      (l1_criterion): L1Loss()
      (duration_criterion): DurationPredictorLoss(
        (criterion): MSELoss()
      )
    )
  )
)

Model summary:
    Class Name: ESPnetSVSModel
    Total Number of model parameters: 35.60 M
    Number of trainable parameters: 35.60 M (100.0%)
    Size: 142.38 MB
    Type: torch.float32
[neptune_wyn_2245] 2022-10-15 17:17:03,971 (abs_task:1161) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-06
    lr: 0.001
    weight_decay: 0.0
)
[neptune_wyn_2245] 2022-10-15 17:17:03,971 (abs_task:1162) INFO: Scheduler: None
[neptune_wyn_2245] 2022-10-15 17:17:03,971 (abs_task:1172) INFO: Saving the configuration in exp/rnn-dp-alf-beat_predict_3/config.yaml
[neptune_wyn_2245] 2022-10-15 17:17:04,483 (abs_task:1526) INFO: [train] dataset:
ESPnetDataset(
  text: {"path": "dump/raw/tr_no_dev/text", "type": "text"}
  singing: {"path": "dump/raw/tr_no_dev/wav.scp", "type": "sound"}
  label: {"path": "dump/raw/tr_no_dev/label", "type": "duration"}
  midi: {"path": "dump/raw/tr_no_dev/xml.scp", "type": "midi"}
  preprocess: <espnet2.train.preprocessor.SVSPreprocessor object at 0x7fcc49d1c390>)
[neptune_wyn_2245] 2022-10-15 17:17:04,483 (abs_task:1527) INFO: [train] Batch sampler: SortedBatchSampler(N-batch=35, batch_size=16, shape_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/train/text_shape.phn, sort_in_batch=descending, sort_batch=descending)
[neptune_wyn_2245] 2022-10-15 17:17:04,483 (abs_task:1529) INFO: [train] mini-batch sizes summary: N-batch=35, mean=16.1, min=16, max=17
[neptune_wyn_2245] 2022-10-15 17:17:04,505 (abs_task:1526) INFO: [valid] dataset:
ESPnetDataset(
  text: {"path": "dump/raw/dev/text", "type": "text"}
  singing: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  label: {"path": "dump/raw/dev/label", "type": "duration"}
  midi: {"path": "dump/raw/dev/xml.scp", "type": "midi"}
  preprocess: <espnet2.train.preprocessor.SVSPreprocessor object at 0x7fcc49ce2f90>)
[neptune_wyn_2245] 2022-10-15 17:17:04,505 (abs_task:1527) INFO: [valid] Batch sampler: SortedBatchSampler(N-batch=4, batch_size=16, shape_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn, sort_in_batch=descending, sort_batch=descending)
[neptune_wyn_2245] 2022-10-15 17:17:04,505 (abs_task:1529) INFO: [valid] mini-batch sizes summary: N-batch=4, mean=16.0, min=16, max=16
[neptune_wyn_2245] 2022-10-15 17:17:04,526 (abs_task:1526) INFO: [plot_att] dataset:
ESPnetDataset(
  text: {"path": "dump/raw/dev/text", "type": "text"}
  singing: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  label: {"path": "dump/raw/dev/label", "type": "duration"}
  midi: {"path": "dump/raw/dev/xml.scp", "type": "midi"}
  preprocess: <espnet2.train.preprocessor.SVSPreprocessor object at 0x7fcc49a046d0>)
[neptune_wyn_2245] 2022-10-15 17:17:04,526 (abs_task:1527) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=64, batch_size=1, key_file=exp/svs_stats_raw_phn_pyopenjtalk_jp/valid/text_shape.phn, 
[neptune_wyn_2245] 2022-10-15 17:17:04,526 (abs_task:1529) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
[neptune_wyn_2245] 2022-10-15 17:17:04,665 (trainer:276) INFO: 1/500epoch started
/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
Traceback (most recent call last):
  File "/root/anaconda3/envs/espnet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/root/anaconda3/envs/espnet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data1/wyn/espnet/espnet2/bin/svs_train.py", line 22, in <module>
    main()
  File "/data1/wyn/espnet/espnet2/bin/svs_train.py", line 18, in main
    SVSTask.main(cmd=cmd)
  File "/data1/wyn/espnet/espnet2/tasks/abs_task.py", line 1019, in main
    cls.main_worker(args)
  File "/data1/wyn/espnet/espnet2/tasks/abs_task.py", line 1323, in main_worker
    distributed_option=distributed_option,
  File "/data1/wyn/espnet/espnet2/train/trainer.py", line 291, in run
    distributed_option=distributed_option,
  File "/data1/wyn/espnet/espnet2/train/trainer.py", line 556, in train_one_epoch
    retval = model(**batch)
  File "/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data1/wyn/espnet/espnet2/svs/espnet_model.py", line 634, in forward
    return self.svs(**batch)
  File "/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data1/wyn/espnet/espnet2/svs/naive_rnn/naive_rnn_dp_alf.py", line 671, in forward
    tempo_emb = self.tempo_encoder_input_layer(tempo)
  File "/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 160, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/root/anaconda3/envs/espnet/lib/python3.7/site-packages/torch/nn/functional.py", line 2043, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)
# Accounting: time=14 threads=1
# Ended (code 1) at Sat Oct 15 17:17:10 UTC 2022, elapsed time 14 seconds

